"""
Sistema de Retroalimentaci贸n con GPT
Genera feedback autom谩tico comparando documentos con r煤bricas
"""
from openai import OpenAI
import json
import os
from typing import Dict, List
from dotenv import load_dotenv
from pathlib import Path

load_dotenv()

class GPTFeedbackGenerator:
    """Genera retroalimentaci贸n acad茅mica usando GPT-4"""

    def __init__(self):
        """Inicializa el cliente de OpenAI"""
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        self.client = OpenAI(api_key=self.openai_api_key)
        self.model = "gpt-4o-mini"  # Opciones: gpt-4o-mini (barato), gpt-4o (mejor calidad)
        self.condiciones_cache = {}  # Cache para condiciones.json

    def generate_criterion_feedback(self, criterion: Dict, document_content: str,
                                    course_name: str, detected_criterion: int = None,
                                    exercises_in_document: list = None, condiciones: Dict = None) -> Dict:
        """
        Genera retroalimentaci贸n para un criterio espec铆fico (NUEVA ESTRUCTURA)
        ACTUALIZADO: Primero verifica si el criterio est谩 presente en el documento

        Args:
            criterion: Dict con estructura del criterio (numero, nombre, niveles, etc.)
            document_content: Contenido del documento del estudiante
            course_name: Nombre del curso
            detected_criterion: N煤mero del criterio detectado desde el nombre del archivo (opcional)
            exercises_in_document: Lista de ejercicios detectados en el documento (opcional)

        Returns:
            Dict con feedback, puntaje y nivel alcanzado (o no_presentado si no aplica)
        """
        try:
            # Extraer informaci贸n del criterio
            criterion_number = criterion['numero']
            criterion_name = criterion['nombre']
            max_score = criterion['puntaje_maximo']
            levels = criterion.get('niveles', [])

            # Usar ejercicios pasados o detectarlos
            if exercises_in_document is None:
                exercises_in_doc = self._detect_exercises_in_document(document_content)
            else:
                exercises_in_doc = exercises_in_document

            print(f"  [EJERCICIOS] Evaluando con ejercicios detectados: {exercises_in_doc}")

            # NUEVA VALIDACIN: Verificar si el criterio est谩 presente en el documento
            # El nombre del archivo es solo una PISTA, NO es definitivo
            is_present = self._is_criterion_present(
                criterion,
                document_content,
                detected_criterion  # Pasar como pista
            )

            if not is_present:
                return {
                    'success': True,
                    'criterion_number': criterion_number,
                    'criterion_name': criterion_name,
                    'max_score': max_score,
                    'score': 0,
                    'level_achieved': 'no_presentado',
                    'feedback': f'No se encontr贸 evidencia de este criterio en el documento. El estudiante no present贸 trabajo relacionado con: {criterion_name}.',
                    'aspects_met': [],
                    'improvements': [
                        f'Incluir evidencia clara de {criterion_name.lower()}',
                        'Asegurarse de cumplir con todos los requisitos de la r煤brica'
                    ]
                }

            # Construir texto de niveles
            levels_text = ""
            for level in levels:
                levels_text += f"\n{level['nivel'].upper()} ({level['puntaje_minimo']}-{level['puntaje_maximo']} pts): {level['descripcion'][:200]}"

            # Informaci贸n de ejercicios detectados
            exercises_info = ""
            if len(exercises_in_doc) > 0:
                exercises_info = f"\n\n[WARN] EJERCICIOS DETECTADOS EN EL DOCUMENTO: {exercises_in_doc}\nEsto significa que el estudiante menciona expl铆citamente estos ejercicios."

            # NUEVO: Obtener tareas detalladas si existen condiciones
            detailed_tasks_info = ""
            if condiciones:
                task_details = self._get_detailed_tasks_for_criterion(criterion_number, condiciones)
                tasks = task_details.get('tasks', [])
                deliverables = task_details.get('deliverables', [])

                if tasks:
                    tasks_text = "\n".join([f"  {i+1}. {task}" for i, task in enumerate(tasks)])
                    detailed_tasks_info += f"\n\n TAREAS ESPECFICAS QUE EL ESTUDIANTE DEBE REALIZAR:\n{tasks_text}"

                if deliverables:
                    deliverables_text = "\n".join([f"  - {d}" for d in deliverables])
                    detailed_tasks_info += f"\n\n ENTREGABLES ESPERADOS:\n{deliverables_text}"

                if tasks or deliverables:
                    detailed_tasks_info += "\n\n[WARN] IMPORTANTE: Verifica PUNTO POR PUNTO si el estudiante cumpli贸 CADA tarea y entreg贸 CADA entregable."

            # Detectar el tipo de criterio para dar instrucciones espec铆ficas
            criterion_type_hint = ""
            if 'dbscan' in criterion_name.lower():
                criterion_type_hint = "\n\n**IMPORTANTE**: Este criterio eval煤a DBSCAN (clustering basado en densidad), NO K-Means ni otros algoritmos. Busca espec铆ficamente: DBSCAN(), eps, min_samples, outliers, noise."
            elif 'k-mean' in criterion_name.lower() or 'kmean' in criterion_name.lower():
                criterion_type_hint = "\n\n**IMPORTANTE**: Este criterio eval煤a K-Means, NO DBSCAN ni otros algoritmos. Busca espec铆ficamente: KMeans(), n_clusters, inertia, elbow, silhouette."
            elif 'agglomerative' in criterion_name.lower():
                criterion_type_hint = "\n\n**IMPORTANTE**: Este criterio eval煤a Agglomerative Clustering (jer谩rquico), NO K-Means ni DBSCAN. Busca espec铆ficamente: AgglomerativeClustering(), dendrogram, linkage."

            # Construir prompt para GPT
            prompt = f"""
Eres un profesor experto y motivador en {course_name}. Eval煤a el siguiente criterio de un trabajo estudiantil con un tono cercano, profesional y constructivo.

CRITERIO {criterion_number}: {criterion_name}
Puntaje m谩ximo: {max_score} puntos
{criterion_type_hint}

NIVELES DE DESEMPEO:
{levels_text}
{detailed_tasks_info}

CONTENIDO DEL DOCUMENTO:
{document_content[:30000]}
{exercises_info}

INSTRUCCIONES PARA GENERAR FEEDBACK:

1. **Verificaci贸n PUNTO POR PUNTO (SI HAY TAREAS ESPECFICAS)**:
   - Revisa CADA tarea de la lista de "TAREAS ESPECFICAS"
   - Para CADA tarea, determina si fue CUMPLIDA, PARCIALMENTE CUMPLIDA o NO CUMPLIDA
   - Busca evidencia CONCRETA en el documento (c贸digo, m茅tricas, gr谩ficos, an谩lisis)
   - Menciona EN EL FEEDBACK cu谩les tareas cumpli贸 y cu谩les no
   - El puntaje debe reflejar el % de tareas cumplidas alineado con los NIVELES DE DESEMPEO

2. **Tono y Estilo**:
   - Usa un tono cercano y motivador (ej: "Excelente trabajo", "Tu implementaci贸n demuestra...", "Se observa que...")
   - S茅 espec铆fico con los datasets, m茅tricas y t茅cnicas que us贸 el estudiante
   - Menciona IDs de datasets si los encuentras (ej: "liver-disorders (ID:8)")
   - Reconoce los logros primero, luego sugiere mejoras

3. **Detecci贸n de Ejercicios**:
   - Busca menciones literales: "Ejercicio 1", "Ejercicio 2", "Ejercicio 3", etc.
   - Si solo present贸 ALGUNOS ejercicios -> Puntaje PROPORCIONAL
   - Menciona EXACTAMENTE cu谩les ejercicios present贸

3. **Estructura del Feedback** (seg煤n el criterio - ADAPTABLE):

   Identifica qu茅 tipo de criterio es bas谩ndote en su nombre/descripci贸n:

   **Si el criterio menciona "carga", "datos", "dataset", "contextualizaci贸n"**:
   - Menciona si explic贸 el prop贸sito/contexto de los datasets
   - Verifica si identific贸 correctamente variables relevantes
   - Revisa si especific贸 caracter铆sticas de los datos

   **Si el criterio menciona "regresi贸n"**:
   - Menciona qu茅 modelos implement贸 (Lineal, Ridge, Lasso, rbol, etc.)
   - Verifica divisi贸n de datos
   - Revisa c谩lculo de m茅tricas (MAE, MSE, RMSE, R虏)
   - Menciona si compar贸 modelos

   **Si el criterio menciona "clasificaci贸n"**:
   - Menciona qu茅 modelos implement贸 (Regresi贸n Log铆stica, rbol, KNN, Perceptr贸n, etc.)
   - Verifica divisi贸n de datos
   - Revisa c谩lculo de m茅tricas (Accuracy, Precision, Recall, F1-score)
   - Verifica matriz de confusi贸n

   **Si el criterio menciona "K-Means" o "k-means"**:
   - Verifica aplicaci贸n en escenarios (2 variables y m谩s variables)
   - Revisa m茅todo del codo y/o Silhouette Score
   - Eval煤a gr谩ficos (scatterplot)
   - Verifica descripci贸n de perfiles de clusters
   - Revisa respuestas a interrogantes

   **Si el criterio menciona "DBSCAN" o "dbscan"**:
   - Verifica correcta aplicaci贸n con variables num茅ricas
   - Revisa justificaci贸n de par谩metros epsilon (系) y min_samples
   - Verifica identificaci贸n de clusters y puntos de ruido
   - Eval煤a descripci贸n de perfiles de clusters
   - Revisa respuestas a interrogantes

   **Si el criterio menciona "Agglomerative" o "jer谩rquico" o "hierarchical"**:
   - Verifica selecci贸n y justificaci贸n de variables
   - Revisa uso de dendrogramas
   - Eval煤a determinaci贸n del n煤mero 贸ptimo de clusters
   - Verifica descripci贸n de perfiles de clusters

   **Si el criterio menciona "foro", "participaci贸n", "feedback", "retroalimentaci贸n"**:
   - Menciona si adjunt贸 screenshot del foro
   - Eval煤a calidad del feedback (constructivo, respetuoso, argumentado)
   - Verifica publicaci贸n de ejercicios

   **Si el criterio menciona "formato", "entrega", "documento"**:
   - Eval煤a estructura, organizaci贸n, claridad
   - Verifica nombre de archivo correcto
   - Revisa cumplimiento de requisitos de entrega

4. **Ejemplos de Feedback Esperado**:
   - "Excelente trabajo en el Ejercicio X, cumples completamente con todos los requisitos solicitados..."
   - "Tu trabajo demuestra dominio t茅cnico en la implementaci贸n de los cuatro modelos..."
   - "El estudiante evidenci贸 su compromiso con la din谩mica del Ejercicio 5..."

FORMATO DE RESPUESTA (JSON):
{{
  "nivel_alcanzado": "<alto/medio/bajo>",
  "puntaje": <n煤mero entre 0 y {max_score}>,
  "feedback": "<feedback detallado, motivador y espec铆fico (2-4 p谩rrafos)>",
  "aspectos_cumplidos": ["<aspecto espec铆fico 1>", "<aspecto espec铆fico 2>", "<aspecto espec铆fico 3>"],
  "mejoras": ["<sugerencia constructiva 1>", "<sugerencia constructiva 2>"]
}}
"""

            # Llamar a GPT
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "Eres un profesor universitario experto, cercano y motivador. Proporcionas retroalimentaci贸n detallada, espec铆fica y constructiva que reconoce logros y gu铆a mejoras."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.4,
                max_tokens=900,
                response_format={"type": "json_object"}
            )

            # Parsear respuesta
            feedback_data = json.loads(response.choices[0].message.content)

            return {
                'success': True,
                'criterion_number': criterion_number,
                'criterion_name': criterion_name,
                'max_score': max_score,
                'score': feedback_data.get('puntaje', 0),
                'level_achieved': feedback_data.get('nivel_alcanzado', 'medio'),
                'feedback': feedback_data.get('feedback', ''),
                'aspects_met': feedback_data.get('aspectos_cumplidos', []),
                'improvements': feedback_data.get('mejoras', [])
            }

        except Exception as e:
            print(f"[ERROR] Error generando feedback para criterio '{criterion_name}': {e}")
            return {
                'success': False,
                'criterion_number': criterion.get('numero', 0),
                'criterion_name': criterion.get('nombre', ''),
                'error': str(e)
            }

    def generate_overall_feedback_criteria(self, course_name: str, criteria_feedbacks: List[Dict],
                                          total_score: float, max_score: int) -> Dict:
        """
        Genera retroalimentaci贸n general usando NUEVA estructura de criterios

        Args:
            course_name: Nombre del curso
            criteria_feedbacks: Lista de feedbacks por criterio
            total_score: Puntaje total obtenido
            max_score: Puntaje m谩ximo posible

        Returns:
            Dict con feedback general y recomendaciones
        """
        try:
            # Resumir resultados por criterio
            criteria_summary = []
            for fb in criteria_feedbacks:
                if fb.get('success'):
                    criteria_summary.append(
                        f"- Criterio {fb['criterion_number']}: {fb['score']}/{fb['max_score']} pts ({fb['level_achieved']})"
                    )

            summary_text = '\n'.join(criteria_summary)
            percentage = (total_score / max_score * 100) if max_score > 0 else 0

            prompt = f"""
Eres un profesor de {course_name}. Proporciona una retroalimentaci贸n GENERAL sobre un trabajo estudiantil.

PUNTAJE FINAL: {total_score}/{max_score} ({percentage:.1f}%)

RESULTADOS POR CRITERIO:
{summary_text}

INSTRUCCIONES:
1. Resume el desempe帽o general del estudiante (m谩ximo 2 p谩rrafos cortos)
2. Destaca 2-3 fortalezas principales
3. Indica 2-3 谩reas de mejora prioritarias
4. Proporciona una conclusi贸n motivadora

FORMATO DE RESPUESTA (JSON):
{{
  "resumen": "<resumen general>",
  "fortalezas": ["<fortaleza 1>", "<fortaleza 2>"],
  "areas_mejora": ["<谩rea 1>", "<谩rea 2>"],
  "conclusion": "<conclusi贸n motivadora>"
}}
"""

            # Llamar a GPT
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "Eres un profesor universitario que proporciona retroalimentaci贸n motivadora y constructiva."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.4,
                max_tokens=600,
                response_format={"type": "json_object"}
            )

            # Parsear respuesta
            overall_data = json.loads(response.choices[0].message.content)

            return {
                'success': True,
                'total_score': total_score,
                'max_score': max_score,
                'percentage': round(percentage, 1),
                'summary': overall_data.get('resumen', ''),
                'strengths': overall_data.get('fortalezas', []),
                'improvement_areas': overall_data.get('areas_mejora', []),
                'conclusion': overall_data.get('conclusion', '')
            }

        except Exception as e:
            print(f"[ERROR] Error generando feedback general: {e}")
            return {
                'success': False,
                'error': str(e)
            }

    def generate_section_feedback(self, section_name: str, section_criteria: List[str],
                                  section_weight: int, document_content: str,
                                  course_name: str) -> Dict:
        """
        Genera retroalimentaci贸n para una secci贸n espec铆fica

        Args:
            section_name: Nombre de la secci贸n
            section_criteria: Lista de criterios de evaluaci贸n
            section_weight: Peso de la secci贸n (%)
            document_content: Contenido del documento del estudiante
            course_name: Nombre del curso

        Returns:
            Dict con feedback, puntaje y recomendaciones
        """
        try:
            # Construir prompt para GPT
            criteria_text = '\n'.join([f"{i+1}. {c}" for i, c in enumerate(section_criteria)])

            prompt = f"""
Eres un profesor experto en {course_name}. Eval煤a la secci贸n "{section_name}" de un trabajo estudiantil.

CRITERIOS DE EVALUACIN (Peso: {section_weight}%):
{criteria_text}

CONTENIDO DEL DOCUMENTO:
{document_content[:3000]}

INSTRUCCIONES:
1. Eval煤a qu茅 criterios se cumplen y cu谩les no
2. Asigna un puntaje de 0-100 para esta secci贸n
3. Proporciona retroalimentaci贸n CONCISA (m谩ximo 3 p谩rrafos cortos)
4. Sugiere 2-3 mejoras espec铆ficas

FORMATO DE RESPUESTA (JSON):
{{
  "puntaje": <n煤mero 0-100>,
  "cumple_criterios": [<lista de criterios cumplidos>],
  "no_cumple_criterios": [<lista de criterios no cumplidos>],
  "feedback": "<retroalimentaci贸n concisa>",
  "mejoras": ["<mejora 1>", "<mejora 2>", "<mejora 3>"]
}}
"""

            # Llamar a GPT
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "Eres un profesor universitario experto que proporciona retroalimentaci贸n constructiva y concisa."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=800,
                response_format={"type": "json_object"}
            )

            # Parsear respuesta
            feedback_data = json.loads(response.choices[0].message.content)

            return {
                'success': True,
                'section': section_name,
                'weight': section_weight,
                'score': feedback_data.get('puntaje', 0),
                'criteria_met': feedback_data.get('cumple_criterios', []),
                'criteria_not_met': feedback_data.get('no_cumple_criterios', []),
                'feedback': feedback_data.get('feedback', ''),
                'improvements': feedback_data.get('mejoras', [])
            }

        except Exception as e:
            print(f"[ERROR] Error generando feedback para secci贸n '{section_name}': {e}")
            return {
                'success': False,
                'section': section_name,
                'error': str(e)
            }

    def generate_overall_feedback(self, course_name: str, section_feedbacks: List[Dict],
                                  total_score: float) -> Dict:
        """
        Genera retroalimentaci贸n general del documento

        Args:
            course_name: Nombre del curso
            section_feedbacks: Lista de feedbacks por secci贸n
            total_score: Puntaje total ponderado

        Returns:
            Dict con feedback general y recomendaciones
        """
        try:
            # Resumir resultados por secci贸n
            sections_summary = []
            for fb in section_feedbacks:
                if fb.get('success'):
                    sections_summary.append(
                        f"- {fb['section']}: {fb['score']}/100 (Peso: {fb['weight']}%)"
                    )

            summary_text = '\n'.join(sections_summary)

            prompt = f"""
Eres un profesor de {course_name}. Proporciona una retroalimentaci贸n GENERAL sobre un trabajo estudiantil.

PUNTAJE FINAL: {total_score:.1f}/100

RESULTADOS POR SECCIN:
{summary_text}

INSTRUCCIONES:
1. Resume el desempe帽o general del estudiante (m谩ximo 2 p谩rrafos cortos)
2. Destaca 2-3 fortalezas principales
3. Indica 2-3 谩reas de mejora prioritarias
4. Proporciona una conclusi贸n motivadora

FORMATO DE RESPUESTA (JSON):
{{
  "resumen": "<resumen general>",
  "fortalezas": ["<fortaleza 1>", "<fortaleza 2>"],
  "areas_mejora": ["<谩rea 1>", "<谩rea 2>"],
  "conclusion": "<conclusi贸n motivadora>"
}}
"""

            # Llamar a GPT
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "Eres un profesor universitario que proporciona retroalimentaci贸n motivadora y constructiva."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.4,
                max_tokens=600,
                response_format={"type": "json_object"}
            )

            # Parsear respuesta
            overall_data = json.loads(response.choices[0].message.content)

            return {
                'success': True,
                'total_score': total_score,
                'summary': overall_data.get('resumen', ''),
                'strengths': overall_data.get('fortalezas', []),
                'improvement_areas': overall_data.get('areas_mejora', []),
                'conclusion': overall_data.get('conclusion', '')
            }

        except Exception as e:
            print(f"[ERROR] Error generando feedback general: {e}")
            return {
                'success': False,
                'error': str(e)
            }

    def evaluate_document(self, document_content: str, rubric_data: Dict,
                         relevant_sections: List[Dict] = None, file_name: str = None) -> Dict:
        """
        Eval煤a un documento completo contra una r煤brica
        SOPORTA NUEVA ESTRUCTURA: criterios_evaluacion

        Args:
            document_content: Contenido extra铆do del documento
            rubric_data: Datos de la r煤brica del curso
            relevant_sections: Secciones relevantes encontradas por Pinecone (opcional)
            file_name: Nombre del archivo subido (para detectar criterio) (opcional)

        Returns:
            Dict con evaluaci贸n completa
        """
        course_name = rubric_data['nombre_curso']

        # NUEVA ESTRUCTURA: criterios_evaluacion (desde PDF)
        if 'criterios_evaluacion' in rubric_data:
            return self._evaluate_with_criteria(document_content, rubric_data, relevant_sections, file_name)

        # ESTRUCTURA ANTIGUA: condiciones_entrega (compatibilidad)
        elif 'condiciones_entrega' in rubric_data:
            return self._evaluate_with_sections(document_content, rubric_data, relevant_sections)

        else:
            return {
                'success': False,
                'error': 'Estructura de r煤brica no reconocida'
            }

    def _evaluate_with_criteria(self, document_content: str, rubric_data: Dict,
                                relevant_sections: List[Dict] = None, file_name: str = None) -> Dict:
        """Eval煤a documento usando NUEVA estructura de criterios"""
        course_name = rubric_data['nombre_curso']
        criteria_to_evaluate = rubric_data['criterios_evaluacion']

        print(f"\n[EVAL] Evaluando documento para: {course_name}")
        print(f"       Archivo: {file_name if file_name else 'Sin nombre'}")
        print(f"       Total criterios: {len(criteria_to_evaluate)}")

        # NUEVO: Cargar condiciones detalladas del curso
        course_folder = self._get_course_folder_from_name(course_name)
        condiciones = self._load_condiciones(course_folder) if course_folder else {}

        if condiciones:
            print(f"       [OK] Condiciones cargadas - Verificacion PUNTO POR PUNTO activada")
        else:
            print(f"       [INFO] Sin condiciones - Evaluacion estandar")

        # PRIMERO: Detectar ejercicios en el documento
        exercises_in_doc = self._detect_exercises_in_document(document_content)
        print(f"       [EJERCICIOS] Detectados en documento: {exercises_in_doc if exercises_in_doc else 'Ninguno'}")

        # Detectar criterio/ejercicio desde nombre del archivo
        detected_criterion = self._detect_criterion_from_filename(file_name) if file_name else None

        # Tambi茅n buscar "Ejercicio X" en el nombre del archivo
        # IGNORAR n煤meros entre par茅ntesis como (2), (1), etc.
        if file_name and not detected_criterion:
            import re
            # Buscar "ejercicio X", "tarea X", etc. pero NO n煤meros entre par茅ntesis
            # Primero eliminar n煤meros entre par茅ntesis del nombre
            clean_name = re.sub(r'\(\d+\)', '', file_name)  # Elimina (1), (2), etc.

            match = re.search(r'ejercicio\s*(\d+)', clean_name.lower())
            if match:
                detected_criterion = int(match.group(1))
                print(f"       [OK] Ejercicio detectado desde nombre archivo: {detected_criterion}")

        if detected_criterion:
            print(f"       [OK] Criterio/Ejercicio detectado desde nombre: {detected_criterion}")
            print(f"       [FILTRADO] Solo se evaluara el Criterio {detected_criterion}")

        # Evaluar cada criterio
        criteria_feedbacks = []
        total_score = 0
        total_max_score = rubric_data.get('puntaje_total', 150)

        for i, criterion in enumerate(criteria_to_evaluate, 1):
            criterion_num = criterion['numero']
            print(f"  [{i}/{len(criteria_to_evaluate)}] Evaluando Criterio {criterion_num}: {criterion['nombre']}...")

            # FILTRO: Si el nombre del archivo indica un criterio espec铆fico
            # Solo evaluar ese criterio (excepto 4 y 5 que siempre se eval煤an)
            if detected_criterion is not None:
                if criterion_num not in [4, 5] and criterion_num != detected_criterion:
                    print(f"  [SKIP] Criterio {criterion_num}: SALTADO (archivo indica Criterio {detected_criterion})")
                    # Crear feedback de NO PRESENTADO
                    feedback = {
                        'success': True,
                        'criterion_number': criterion_num,
                        'criterion_name': criterion['nombre'],
                        'max_score': criterion['puntaje_maximo'],
                        'score': 0,
                        'level_achieved': 'no_presentado',
                        'feedback': f'El nombre del archivo indica que este documento corresponde al Criterio/Ejercicio {detected_criterion}, no al Criterio {criterion_num}.',
                        'aspects_met': [],
                        'improvements': [f'Subir documento espec铆fico para el Criterio {criterion_num}']
                    }
                    criteria_feedbacks.append(feedback)
                    continue

            # Generar feedback para este criterio
            feedback = self.generate_criterion_feedback(
                criterion=criterion,
                document_content=document_content,
                course_name=course_name,
                detected_criterion=detected_criterion,  # NUEVO
                exercises_in_document=exercises_in_doc,  # NUEVO
                condiciones=condiciones  # NUEVO: Pasar condiciones para verificaci贸n detallada
            )

            if feedback.get('success'):
                criteria_feedbacks.append(feedback)
                total_score += feedback['score']
            else:
                print(f"  [ERROR] Error en criterio: {criterion['nombre']}")

        # Generar retroalimentaci贸n general
        print(f"\n  [GENERAL] Generando feedback general...")
        overall_feedback = self.generate_overall_feedback_criteria(
            course_name=course_name,
            criteria_feedbacks=criteria_feedbacks,
            total_score=total_score,
            max_score=total_max_score
        )

        return {
            'success': True,
            'course': course_name,
            'total_score': round(total_score, 1),
            'max_score': total_max_score,
            'criteria_feedbacks': criteria_feedbacks,
            'overall_feedback': overall_feedback,
            'timestamp': self._get_timestamp()
        }

    def _evaluate_with_sections(self, document_content: str, rubric_data: Dict,
                               relevant_sections: List[Dict] = None) -> Dict:
        """Eval煤a documento usando ESTRUCTURA ANTIGUA de secciones"""
        course_name = rubric_data['nombre_curso']
        sections_to_evaluate = rubric_data['condiciones_entrega']

        # Si hay secciones relevantes de Pinecone, priorizarlas
        if relevant_sections:
            print(f"[INFO] Priorizando {len(relevant_sections)} secciones relevantes")
            # Ordenar por relevancia
            relevant_sections.sort(key=lambda x: x['relevance_score'], reverse=True)

        print(f"\n[EVAL] Evaluando documento para: {course_name}")
        print(f"       Total secciones: {len(sections_to_evaluate)}")

        # Evaluar cada secci贸n
        section_feedbacks = []
        total_weighted_score = 0

        for i, section in enumerate(sections_to_evaluate, 1):
            print(f"  [{i}/{len(sections_to_evaluate)}] Evaluando: {section['seccion']}...")

            feedback = self.generate_section_feedback(
                section_name=section['seccion'],
                section_criteria=section['criterios'],
                section_weight=section['peso'],
                document_content=document_content,
                course_name=course_name
            )

            if feedback.get('success'):
                section_feedbacks.append(feedback)
                # Calcular puntaje ponderado
                weighted_score = (feedback['score'] / 100) * section['peso']
                total_weighted_score += weighted_score
            else:
                print(f"  [ERROR] Error en seccion: {section['seccion']}")

        # Generar retroalimentaci贸n general
        print(f"\n  [GENERAL] Generando feedback general...")
        overall_feedback = self.generate_overall_feedback(
            course_name=course_name,
            section_feedbacks=section_feedbacks,
            total_score=total_weighted_score
        )

        return {
            'success': True,
            'course': course_name,
            'total_score': round(total_weighted_score, 1),
            'section_feedbacks': section_feedbacks,
            'overall_feedback': overall_feedback,
            'timestamp': self._get_timestamp()
        }

    def _detect_exercises_in_document(self, document_content: str) -> list:
        """
        Detecta qu茅 ejercicios est谩n presentes en el documento buscando literalmente
        "Ejercicio 1", "Ejercicio 2", etc.

        VERSIN MEJORADA: Maneja saltos de l铆nea y espacios del OCR

        Returns:
            Lista de n煤meros de ejercicios encontrados (ej: [1, 2, 5])
        """
        import re

        doc_lower = document_content.lower()
        exercises_found = []

        # Patrones FLEXIBLES para buscar ejercicios (permiten saltos de l铆nea y m煤ltiples espacios)
        patterns = [
            r'ejercicio[\s\n\r]*(\d+)',      # Ejercicio 1, Ejercicio\n1, etc.
            r'exercise[\s\n\r]*(\d+)',
            r'actividad[\s\n\r]*(\d+)',
            r'activity[\s\n\r]*(\d+)',
            r'punto[\s\n\r]*(\d+)',
            r'item[\s\n\r]*(\d+)',
            r'tarea[\s\n\r]*(\d+)',
            r'task[\s\n\r]*(\d+)',
        ]

        for pattern in patterns:
            matches = re.finditer(pattern, doc_lower, re.MULTILINE)
            for match in matches:
                exercise_num = int(match.group(1))
                if exercise_num not in exercises_found and 1 <= exercise_num <= 10:
                    exercises_found.append(exercise_num)

        return sorted(exercises_found)

    def _is_criterion_present(self, criterion: Dict, document_content: str, detected_criterion: int = None) -> bool:
        """
        Verifica si un criterio espec铆fico est谩 presente en el documento usando GPT
        VERSIN BALANCEADA: Usa keywords + GPT, con el nombre del archivo como PISTA

        Args:
            criterion: Dict con informaci贸n del criterio
            document_content: Contenido del documento
            detected_criterion: Criterio detectado desde nombre archivo (PISTA, no absoluto)

        Returns:
            True si el criterio est谩 presente, False si no
        """
        try:
            criterion_name = criterion['nombre']
            criterion_num = criterion.get('numero', 0)

            # PISTA POSITIVA: Si el nombre del archivo indica ESTE criterio -> Facilitar detecci贸n
            file_hint_matches = (detected_criterion is not None and detected_criterion == criterion_num)

            # Detectar ejercicios presentes en el documento
            exercises_in_doc = self._detect_exercises_in_document(document_content)

            print(f"\n  [DEBUG] Criterio {criterion_num}:")
            print(f"    - detected_criterion: {detected_criterion}")
            print(f"    - file_hint_matches: {file_hint_matches}")
            print(f"    - exercises_found: {exercises_in_doc}")

            if file_hint_matches:
                print(f"  [INFO] Criterio {criterion_num}: Nombre del archivo indica este criterio (PISTA POSITIVA)")

            # DETECCIN DIRECTA POR EJERCICIOS
            # Si encuentra "Ejercicio X" en el documento, asumir que el criterio est谩 presente
            if len(exercises_in_doc) > 0:
                # Si este criterio est谩 en la lista de ejercicios detectados, PRESENTE
                if criterion_num in exercises_in_doc:
                    print(f"  [OK] Criterio {criterion_num}: Encontr贸 Ejercicio {criterion_num} en el documento -> PRESENTE")
                    return True
                else:
                    print(f"  [WARN] Criterio {criterion_num}: Ejercicios detectados {exercises_in_doc}, pero no incluye {criterion_num}")

            # Keywords DINMICAS basadas en el nombre del criterio
            # Detectar autom谩ticamente si es Fase 2 (Regresi贸n/Clasificaci贸n) o Fase 3 (Clustering)
            criterion_name_lower = criterion_name.lower()

            # FASE 3: Clustering (K-Means, DBSCAN, Agglomerative)
            if 'k-mean' in criterion_name_lower or 'kmean' in criterion_name_lower:
                required_keywords = {
                    criterion_num: [
                        ['kmeans', 'k-means', 'k_means', 'cluster', 'agrupamiento'],
                        ['elbow', 'codo', 'silhouette', 'inertia'],
                    ]
                }
            elif 'dbscan' in criterion_name_lower:
                required_keywords = {
                    criterion_num: [
                        ['dbscan', 'db-scan', 'db_scan', 'cluster', 'agrupamiento'],
                        ['epsilon', 'eps', 'min_samples', 'ruido', 'noise', 'outlier'],
                    ]
                }
            elif 'agglomerative' in criterion_name_lower or 'jer谩rquico' in criterion_name_lower or 'hierarchical' in criterion_name_lower:
                required_keywords = {
                    criterion_num: [
                        ['agglomerative', 'hierarchical', 'jer谩rquico', 'cluster', 'agrupamiento'],
                        ['dendrograma', 'dendrogram', 'linkage'],
                    ]
                }
            # FASE 2: Regresi贸n y Clasificaci贸n
            elif 'regresi贸n' in criterion_name_lower or 'regression' in criterion_name_lower:
                required_keywords = {
                    criterion_num: [
                        ['regresi贸n', 'regression', 'regressor', 'predic'],
                        ['MAE', 'MSE', 'RMSE', 'R虏', 'r2', 'error', 'm茅trica'],
                    ]
                }
            elif 'clasificaci贸n' in criterion_name_lower or 'classification' in criterion_name_lower:
                required_keywords = {
                    criterion_num: [
                        ['clasificaci贸n', 'classification', 'classifier', 'clase'],
                        ['accuracy', 'precision', 'recall', 'F1', 'score', 'exactitud'],
                    ]
                }
            # GENRICOS (Foro, Formato, Carga de datos)
            else:
                required_keywords = {
                    1: [
                        ['dataset', 'datos', 'data', 'csv', 'archivo'],
                        ['carga', 'load', 'read_csv', 'lectura'],
                    ],
                    4: [
                        ['foro', 'forum', 'participaci贸n', 'comentario'],
                    ],
                    5: [
                        ['documento', 'entrega', 'formato', 'archivo']
                    ]
                }

            # Keywords DE EXCLUSIN (si est谩n presentes, DESCARTAR el criterio)
            exclusion_keywords = {
                1: ['regresi贸n', 'regression', 'clasificaci贸n', 'classification', 'MAE', 'MSE', 'accuracy', 'precision', 'recall'],  # Si tiene modelos -> NO es solo Criterio 1
                2: ['clasificaci贸n', 'classification', 'accuracy', 'precision', 'recall', 'F1'],  # Si tiene clasificaci贸n -> NO es Criterio 2
                3: ['regresi贸n', 'regression', 'MAE', 'MSE', 'RMSE']  # Si SOLO tiene regresi贸n -> NO es Criterio 3
            }

            doc_lower = document_content.lower()

            # FASE 0: DESHABILITADA - No usar exclusiones autom谩ticas
            # Permitir que GPT decida basado en el contenido completo
            # (Las exclusiones eran demasiado agresivas para trabajos completos)

            # FASE 1: Verificaci贸n r谩pida de keywords obligatorias
            required_groups = required_keywords.get(criterion_num, [])
            groups_matched = 0

            for group in required_groups:
                if any(kw.lower() in doc_lower for kw in group):
                    groups_matched += 1

            # DETECCIN ESPECIAL PARA DBSCAN: Si encuentra "DBSCAN" en el c贸digo, ACEPTAR INMEDIATAMENTE
            if 'dbscan' in criterion_name_lower and 'dbscan' in doc_lower:
                print(f"  [OK] Criterio {criterion_num}: Encontr贸 'DBSCAN' en el documento -> PRESENTE (detecci贸n directa)")
                return True

            # DETECCIN ESPECIAL PARA K-MEANS: Si encuentra "kmeans" en el c贸digo, ACEPTAR INMEDIATAMENTE
            if ('k-mean' in criterion_name_lower or 'kmean' in criterion_name_lower) and ('kmeans' in doc_lower or 'k-means' in doc_lower):
                print(f"  [OK] Criterio {criterion_num}: Encontr贸 'KMeans' en el documento -> PRESENTE (detecci贸n directa)")
                return True

            # DETECCIN ESPECIAL PARA AGGLOMERATIVE: Si encuentra "agglomerative" en el c贸digo, ACEPTAR INMEDIATAMENTE
            if 'agglomerative' in criterion_name_lower and 'agglomerative' in doc_lower:
                print(f"  [OK] Criterio {criterion_num}: Encontr贸 'Agglomerative' en el documento -> PRESENTE (detecci贸n directa)")
                return True

            # Ajustar requisitos seg煤n pista de archivo
            # AHORA MS FLEXIBLE: Solo necesita 1 grupo en general
            if file_hint_matches:
                min_groups = 1  # Con pista: 1 grupo
            else:
                # Sin pista: Tambi茅n 1 grupo (MUY FLEXIBLE para permitir trabajos completos)
                min_groups = 1

            if groups_matched < min_groups:
                print(f"  [ERROR] Criterio {criterion_num}: Solo {groups_matched}/{len(required_groups)} grupos obligatorios -> NO PRESENTADO")
                return False

            print(f"  [OK] Criterio {criterion_num}: Encontr贸 {groups_matched}/{len(required_groups)} grupos de keywords (m铆nimo: {min_groups})")

            # FASE 2: Validaci贸n con GPT
            # Si NO hay criterio detectado desde archivo, ser MUY PERMISIVO (trabajo completo)
            if detected_criterion is None:
                strictness = "PERMISIVO: Da el beneficio de la duda. Si hay CUALQUIER evidencia m铆nima del criterio, marca como PRESENTE."
            else:
                strictness = "BALANCEADO: Busca evidencia razonable del criterio."

            prompt = f"""
Eres un evaluador acad茅mico {strictness}

Determina si el siguiente documento contiene evidencia del criterio:

CRITERIO {criterion_num}: "{criterion_name}"

DOCUMENTO COMPLETO:
{document_content[:30000]}

INSTRUCCIONES ADAPTABLES seg煤n el nombre del criterio:

**Si el criterio menciona "K-Means" o "k-means"**:
- Busca: Implementaci贸n de K-Means, m茅todo del codo, Silhouette Score, selecci贸n de n煤mero de clusters, perfiles de clusters
- C贸digo Python: KMeans(), inertia, silhouette_score
- Si encuentra esta implementaci贸n -> TRUE

**Si el criterio menciona "DBSCAN"**:
- Busca: Implementaci贸n de DBSCAN, selecci贸n de epsilon y min_samples, identificaci贸n de clusters y puntos de ruido
- C贸digo Python: DBSCAN(), eps, min_samples, labels, outliers, noise
- IMPORTANTE: Busca tambi茅n preparaci贸n de datos (StandardScaler, variables num茅ricas)
- Si encuentra esta implementaci贸n -> TRUE

**Si el criterio menciona "Agglomerative" o "jer谩rquico"**:
- Busca: Implementaci贸n de Agglomerative Clustering, dendrogramas, selecci贸n de variables, n煤mero 贸ptimo de clusters
- C贸digo Python: AgglomerativeClustering(), dendrogram, linkage
- Si encuentra esta implementaci贸n -> TRUE

**Si el criterio menciona "regresi贸n"**:
- Busca: Implementaci贸n de regresi贸n, m茅tricas (MAE, MSE, RMSE, R虏)
- Si encuentra modelos de regresi贸n -> TRUE

**Si el criterio menciona "clasificaci贸n"**:
- Busca: Implementaci贸n de clasificaci贸n, m茅tricas (accuracy, precision, recall, F1)
- Si encuentra modelos de clasificaci贸n -> TRUE

**Si el criterio menciona "foro" o "participaci贸n"**:
- Busca: Menciones de foro, retroalimentaci贸n, participaci贸n, screenshot
- Si encuentra participaci贸n -> TRUE

**Si el criterio menciona "formato" o "entrega"**:
- Siempre TRUE (eval煤a formato del documento)

IMPORTANTE: Si encuentras evidencia razonable del criterio, marca como TRUE.
No seas demasiado estricto. Si hay dudas, da el beneficio de la duda al estudiante.

Responde SOLO con JSON:
{{
  "presente": true/false,
  "razon": "<explicaci贸n breve>",
  "confianza": "<alta/media/baja>"
}}
"""
            # Sistema de evaluaci贸n seg煤n contexto
            if detected_criterion is None:
                system_msg = "Eres un evaluador acad茅mico MUY PERMISIVO. El estudiante present贸 un trabajo completo. Marca 'presente: true' si encuentras CUALQUIER evidencia del criterio, por m铆nima que sea."
            else:
                system_msg = "Eres un evaluador acad茅mico JUSTO. Marca 'presente: true' si hay evidencia razonable del criterio."

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_msg},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.0,  # M谩s determin铆stico
                max_tokens=200,
                response_format={"type": "json_object"}
            )

            result = json.loads(response.choices[0].message.content)
            is_present = result.get('presente', False)
            confidence = result.get('confianza', 'baja')
            reason = result.get('razon', '')

            # DECISIN FINAL: Combinar keywords + GPT + pista de archivo
            # Si GPT dice que NO est谩 presente, rechazar inmediatamente
            if not is_present:
                # PERO: Si el nombre del archivo coincide, dar una segunda oportunidad
                if file_hint_matches:
                    print(f"  [WARN] Criterio {criterion_num}: GPT dice NO PRESENTE pero archivo indica este criterio")
                    print(f"     -> ACEPTAR por pista de archivo (raz贸n GPT: {reason[:80]})")
                    return True
                else:
                    print(f"  [ERROR] Criterio {criterion_num}: GPT confirm贸 NO PRESENTE -> {reason}")
                    return False

            # Si GPT dice S pero con confianza BAJA
            if is_present and confidence == 'baja':
                # Si hay pista de archivo, ACEPTAR igual
                if file_hint_matches:
                    print(f"  [OK] Criterio {criterion_num}: Confianza baja pero archivo coincide -> ACEPTAR")
                    return True
                else:
                    print(f"  [WARN] Criterio {criterion_num}: GPT dice PRESENTE pero confianza BAJA -> NO PRESENTADO ({reason})")
                    return False

            # Si lleg贸 aqu铆: GPT confirm贸 con confianza media/alta
            print(f"  [OK] Criterio {criterion_num}: PRESENTE confirmado (grupos: {groups_matched}, confianza: {confidence})")
            print(f"     Raz贸n: {reason[:100]}")
            return True

        except Exception as e:
            print(f"[WARN] Error verificando presencia del criterio: {e}")
            # En caso de error, RECHAZAR por defecto (modo estricto)
            return False

    def _detect_criterion_from_filename(self, file_name: str) -> int:
        """
        Detecta el n煤mero de criterio/tarea desde el nombre del archivo
        Ignora n煤meros entre par茅ntesis como (1), (2), etc.

        Args:
            file_name: Nombre del archivo (ej: "tarea_2.pdf", "criterio3.ipynb", "ejercicio_1.png")

        Returns:
            N煤mero del criterio detectado (1-5) o None si no se detecta
        """
        import re

        if not file_name:
            return None

        # Eliminar n煤meros entre par茅ntesis primero (para evitar confusi贸n con versiones)
        file_lower = re.sub(r'\(\d+\)', '', file_name.lower())

        # Patrones para detectar criterio/tarea/ejercicio
        # IMPORTANTE: Usar \b (word boundary) para evitar coincidencias dentro de palabras como "Fase2"
        patterns = [
            r'criterio[_\s-]?(\d)',
            r'tarea[_\s-]?(\d)',
            r'ejercicio[_\s-]?(\d)',
            r'actividad[_\s-]?(\d)',
            r'punto[_\s-]?(\d)',
            r'task[_\s-]?(\d)',
            r'criterion[_\s-]?(\d)',
            r'activity[_\s-]?(\d)',
            r'\bc(\d)',  # c1, c2, c3 (solo al inicio de palabra)
            r'\bt(\d)',  # t1, t2, t3 (solo al inicio de palabra)
            r'\be(\d)',  # e1, e2, e3 (solo al inicio de palabra)
        ]

        for pattern in patterns:
            match = re.search(pattern, file_lower)
            if match:
                criterion_num = int(match.group(1))
                # Validar que sea un n煤mero v谩lido (1-5)
                if 1 <= criterion_num <= 5:
                    return criterion_num

        return None

    def _get_timestamp(self) -> str:
        """Retorna timestamp actual"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    def _load_condiciones(self, course_folder: str) -> Dict:
        """
        Carga el archivo condiciones.json de un curso

        Args:
            course_folder: Nombre de la carpeta del curso (ej: 'machine_learning_fase3')

        Returns:
            Dict con las condiciones o dict vac铆o si no existe
        """
        # Verificar cache
        if course_folder in self.condiciones_cache:
            return self.condiciones_cache[course_folder]

        # Buscar archivo condiciones.json
        condiciones_path = Path(f"courses/{course_folder}/condiciones.json")

        if not condiciones_path.exists():
            print(f"  [INFO] No se encontr贸 condiciones.json para {course_folder}")
            return {}

        try:
            with open(condiciones_path, 'r', encoding='utf-8') as f:
                condiciones = json.load(f)
                self.condiciones_cache[course_folder] = condiciones
                print(f"  [OK] Cargadas condiciones para {course_folder}")
                return condiciones
        except Exception as e:
            print(f"  [ERROR] Error cargando condiciones: {e}")
            return {}

    def _get_detailed_tasks_for_criterion(self, criterion_num: int, condiciones: Dict) -> Dict:
        """
        Obtiene las tareas detalladas para un criterio espec铆fico

        Args:
            criterion_num: N煤mero del criterio (1, 2, 3, etc.)
            condiciones: Dict con las condiciones del curso

        Returns:
            Dict con:
            - tasks: list (lista de tareas espec铆ficas)
            - deliverables: list (entregables esperados)
            - description: str (descripci贸n del ejercicio)
        """
        if not condiciones or 'ejercicios' not in condiciones:
            return {'tasks': [], 'deliverables': [], 'description': ''}

        # Buscar el ejercicio correspondiente
        for ejercicio in condiciones['ejercicios']:
            if ejercicio.get('numero') == criterion_num:
                tasks = []
                deliverables = ejercicio.get('entregables', [])
                description = ejercicio.get('descripcion', '')

                # Tareas directas
                if 'tareas' in ejercicio:
                    tasks.extend(ejercicio['tareas'])

                # Si tiene escenarios (como K-Means)
                if 'escenarios' in ejercicio:
                    for escenario in ejercicio['escenarios']:
                        escenario_num = escenario.get('escenario', 0)
                        escenario_nombre = escenario.get('nombre', f'Escenario {escenario_num}')

                        if 'tareas' in escenario:
                            for tarea in escenario['tareas']:
                                tasks.append(f"[{escenario_nombre}] {tarea}")

                return {
                    'tasks': tasks,
                    'deliverables': deliverables,
                    'description': description
                }

        return {'tasks': [], 'deliverables': [], 'description': ''}

    def _get_course_folder_from_name(self, course_name: str) -> str:
        """
        Obtiene el nombre de la carpeta del curso desde el nombre del curso

        Args:
            course_name: Nombre del curso (ej: "Machine Learning - Fase 3")

        Returns:
            Nombre de la carpeta (ej: "machine_learning_fase3")
        """
        # Mapeo de nombres de curso a carpetas
        mappings = {
            'Machine Learning - Fase 2': 'machine_learning',
            'Machine Learning - Fase 3': 'machine_learning_fase3',
            'Machine Learning': 'machine_learning',
            'Big Data Integration': 'big_data_integration'
        }

        return mappings.get(course_name, '')


if __name__ == "__main__":
    # Test del generador de feedback
    print("=== Test GPT Feedback Generator ===\n")

    generator = GPTFeedbackGenerator()

    # Cargar r煤brica de ejemplo
    rubric_path = "../courses/machine_learning/condiciones.json"
    with open(rubric_path, 'r', encoding='utf-8') as f:
        rubric = json.load(f)

    # Documento de ejemplo
    test_document = """
    # Proyecto de Machine Learning: Predicci贸n de Precios

    ## Introducci贸n
    Este proyecto aborda el problema de predecir precios de casas usando regresi贸n.
    El objetivo es crear un modelo preciso que ayude a estimar valores de propiedades.

    ## Exploraci贸n de Datos
    El dataset contiene 1000 registros con 15 features.
    Se identificaron 20 valores faltantes y 3 outliers.
    La correlaci贸n entre 谩rea y precio es 0.85.

    ## Modelado
    import pandas as pd
    from sklearn.linear_model import LinearRegression
    from sklearn.ensemble import RandomForestRegressor

    # Modelo entrenado con 80/20 split
    model = RandomForestRegressor(n_estimators=100)
    model.fit(X_train, y_train)

    ## Resultados
    RMSE: 15000
    R虏: 0.82
    """

    # Evaluar documento
    result = generator.evaluate_document(test_document, rubric)

    if result['success']:
        print(f"\n[OK] Evaluaci贸n completada")
        print(f"  - Puntaje total: {result['total_score']}/100")
        print(f"  - Secciones evaluadas: {len(result['section_feedbacks'])}")
        print(f"\n  Feedback general:")
        print(f"  {result['overall_feedback']['summary'][:200]}...")
    else:
        print(f"[ERROR] Error en evaluaci贸n")
